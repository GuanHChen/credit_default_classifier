CREDIT CARD DEFAULT FEATURES

LIMIT_BAL: Credit Limit in NT
SEX: Gender (1=male, 2=female)
EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)
MARRIAGE: Marital status (1=married, 2=single, 3=others)
AGE: Age
PAY_0: Repayment status in September, 2005 (-2= no consumption, -1=pay duly, 1=payment delay for one month, 2=payment delay for two months, â€¦ 8=payment delay for eight months, 9=payment delay for nine months and above)
PAY_2: Repayment status in August, 2005 (scale same as above)
PAY_3: Repayment status in July, 2005 (scale same as above)
PAY_4: Repayment status in June, 2005 (scale same as above)
PAY_5: Repayment status in May, 2005 (scale same as above)
PAY_6: Repayment status in April, 2005 (scale same as above)
BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)
BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)
BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)
BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)
BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)
BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)
PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)
PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)
PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)
PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)
PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)
PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)
default.payment.next.month: Default payment (1=yes, 0=no)

Encoding Categorical Variables
Binary Encoding of Sex:
0 = Female     1 = Male

Ordinal Encoding of Education:
0 = Unknown      1 = High School        2 = University      3 = Graduate School

One Hot Encoding of Marriage

Step 3: Feature Engineering
Credit Util (Avg)
Late Payment Count
Bill Variance (capture spikes in spending / erratic spending behavior)

Step 4: Feature Scaling
normalize all numerical data

Step 5: Feature Selection

Step 6: Model Optimizations
Resampling
K Fold Cross Validation
Pruning
Boosting
Bagging
Random Forest / Ensemble
Credit Utilization Filter
Downsampling



param_grid = [{
    'n_estimators': [250, 500, 750, 1000, 1250, 1500],
    'criterion': ['entropy', 'gini'],
    'min_samples_split': [10, 100, 1000],
    'min_samples_leaf': [10, 25, 100],
    'max_depth': [10, 20, 30]
}]

grid_search = GridSearchCV(rf,
    param_grid,
    cv=5,
    scoring=['roc_auc', 'f1'],
    refit='roc_auc',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_val, y_val)
print(grid_search.best_score_) # 0.7861319869359884
print(grid_search.best_params_) # {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 10, 'min_samples_split': 100, 'n_estimators': 1500}
